# Quiz03-[Practice]-value-Functions-and-Bellman-Equations

## 1. A policy is a function which maps \____ to \____.

![image-20201229225244905](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225244905.png)

## 2. The term “backup” most closely resembles the term ___ in meaning.

![image-20201229225300833](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225300833.png)



## 3. At least one deterministic optimal policy exists in every Markov decision process.

![image-20201229225321650](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225321650.png)



## 4. The optimal state-value function:

![image-20201229225352094](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225352094.png)



## 5. Does adding a constant to all rewards change the set of optimal policies in episodic tasks?

![image-20201229225411721](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225411721.png)



## 6. Does adding a constant to all rewards change the set of optimal policies in continuing tasks?

![image-20201229225431565](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225431565.png)

## 7. Select the equation that correctly relates $v_{\ast}$. Assume $\pi$ is the uniform random policy.
![image-20201229225542663](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225542663.png)



## 8. Select the equation that correctly relates $q_{\ast}$ to $v_{\ast}$ using  four-argument function $p$. 
![image-20201229225644810](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225644810.png)



## 9. Write a policy $\pi_{\ast}$ in terms of $q_{\ast}$.

![image-20201229225726222](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225726222.png)



## 10. Give an equation for some $\pi_{\ast}$ in terms of $v_{\ast}$ and the four-argument $p$.

![image-20201229225809271](C:\Users\Helia\AppData\Roaming\Typora\typora-user-images\image-20201229225809271.png)